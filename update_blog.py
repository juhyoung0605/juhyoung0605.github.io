import feedparser
import datetime
import os
import re
from urllib.parse import urlparse
from xml.sax.saxutils import escape

# =========================
# ì„¤ì •
# =========================
RSS_URL = "https://rss.blog.naver.com/jubro_0605.xml"
BASE_URL = "https://juhyoung0605.github.io"
POST_DIR = "posts"

INDEX_FILE = "index.html"
POSTS_FILE = "posts.html"
SITEMAP_FILE = "sitemap.xml"
ROBOTS_FILE = "robots.txt"

MAX_INDEX_POSTS = 5

os.makedirs(POST_DIR, exist_ok=True)

# =========================
# RSS íŒŒì‹±
# =========================
feed = feedparser.parse(RSS_URL)

posts_meta = []

for entry in feed.entries:
    if not hasattr(entry, "published"):
        continue

    dt = datetime.datetime.strptime(
        entry.published, "%a, %d %b %Y %H:%M:%S %z"
    )
    date_str = dt.strftime("%Y-%m-%d")
    safe_title = re.sub(r"[^\w\-]", "", entry.title.replace(" ", "-")).lower()
    filename = f"{date_str}-{safe_title}.html"
    filepath = os.path.join(POST_DIR, filename)

    summary = re.sub("<[^<]+?>", "", entry.description)
    summary = summary.replace("&nbsp;", " ").strip()

    # posts ê°œë³„ html ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ)
    if not os.path.exists(filepath):
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"""<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>{entry.title}</title>
  <meta name="description" content="{summary[:150]}">
  <link rel="canonical" href="{entry.link}">
</head>
<body>
  <h1>{entry.title}</h1>
  <p><a href="{entry.link}" target="_blank">ğŸ‘‰ ë„¤ì´ë²„ ì›ë¬¸ ë³´ê¸°</a></p>
  <p>{summary}</p>
</body>
</html>
""")

    posts_meta.append({
        "title": entry.title,
        "date": date_str,
        "summary": summary[:120] + "...",
        "file": f"{POST_DIR}/{filename}"
    })

# ìµœì‹ ìˆœ ì •ë ¬
posts_meta.sort(key=lambda x: x["date"], reverse=True)

# =========================
# index.html ìƒì„±
# =========================
index_items = ""
for post in posts_meta[:MAX_INDEX_POSTS]:
    index_items += f"""
<li>
  <a href="{post['file']}">{post['title']}</a><br>
  <small>{post['date']} Â· {post['summary']}</small>
</li>
"""

with open(INDEX_FILE, "w", encoding="utf-8") as f:
    f.write(f"""<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì•„ì¹´ì´ë¸Œ</title>
  <meta name="description" content="ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ì„ ìë™ìœ¼ë¡œ ì•„ì¹´ì´ë¹™í•œ ì‚¬ì´íŠ¸">
</head>
<body>
  <h1>ìµœê·¼ ê¸€</h1>
  <ul>{index_items}</ul>
  <p><a href="posts.html">ğŸ“š ì „ì²´ ê¸€ ë³´ê¸°</a></p>
</body>
</html>
""")

# =========================
# posts.html ìƒì„±
# =========================
posts_items = ""
for post in posts_meta:
    posts_items += f"""
<li>
  <a href="{post['file']}">{post['title']}</a>
  <small>({post['date']})</small>
</li>
"""

with open(POSTS_FILE, "w", encoding="utf-8") as f:
    f.write(f"""<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>ì „ì²´ ê¸€ ëª©ë¡</title>
</head>
<body>
  <h1>ì „ì²´ ê¸€</h1>
  <ul>{posts_items}</ul>
  <p><a href="index.html">â† í™ˆìœ¼ë¡œ</a></p>
</body>
</html>
""")

# =========================
# sitemap.xml ìƒì„±
# =========================
with open(SITEMAP_FILE, "w", encoding="utf-8") as f:
    f.write("""<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
""")

    def add_url(loc):
        f.write(f"""  <url>
    <loc>{escape(loc)}</loc>
  </url>
""")

    add_url(BASE_URL + "/")
    add_url(BASE_URL + "/posts.html")

    for post in posts_meta:
        add_url(f"{BASE_URL}/{post['file']}")

    f.write("</urlset>")

# =========================
# robots.txt ìƒì„±
# =========================
with open(ROBOTS_FILE, "w", encoding="utf-8") as f:
    f.write(f"""User-agent: *
Allow: /

Sitemap: {BASE_URL}/sitemap.xml
""")

print("âœ… ì „ì²´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
